<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Processing Code Snippets</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            background-color: #f4f4f9;
        }
        h1 {
            text-align: center;
            color: #333;
        }
        .code-section {
            background: #fff;
            border: 1px solid #ddd;
            border-radius: 8px;
            margin-bottom: 20px;
            padding: 15px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }
        .code-section h2 {
            font-size: 1.2rem;
            margin-top: 0;
            color: #444;
        }
        .code-section p {
            color: #555;
        }
        .code-block {
            background: #f9f9f9;
            border: 1px solid #eee;
            padding: 10px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: "Courier New", Courier, monospace;
            color: #333;
        }
        .code-block pre {
            margin: 0;
        }
    </style>
</head>
<body>
    <h1>Image Processing Code Snippets</h1>

    <div class="code-section">
        <h2>1. Basic Image Processing</h2>
        <p>This snippet performs grayscale conversion, edge detection, image scaling, resizing, Gaussian blur, and thresholding.</p>
        <div class="code-block">
            <pre>
import cv2
import numpy as np
from google.colab.patches import cv2_imshow
image = cv2.imread("chessboard.jpg")

gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
edges_image = cv2.Canny(image,50,150)
scaled_image = image[150:400,150:400]
resize_image = cv2.resize(image,(200,200))
blurr_image = cv2.GaussianBlur(image,(5,5),0)
_,binary_image = cv2.threshold(gray,178,255,cv2.THRESH_BINARY)
cv2_imshow(gray_image)
cv2_imshow(edges_image)
cv2_imshow(scaled_image)
cv2_imshow(resize_image)
cv2_imshow(blurr_image)
cv2_imshow(binary_image)
            </pre>
        </div>
    </div>

    <div class="code-section">
        <h2>2. Watershed Algorithm</h2>
        <p>This snippet uses the Watershed algorithm for image segmentation.</p>
        <div class="code-block">
            <pre>
import cv2
import numpy as np
import matplotlib.pyplot as plt
image = cv2.imread('fruit.jpg')
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
edges = cv2.Canny(gray, 50, 150)
kernel = np.ones((3, 3), np.uint8)
dilated = cv2.dilate(edges, kernel, iterations=2)
_, markers = cv2.connectedComponents(dilated)
markers += 1
markers[dilated == 0] = 0
markers = cv2.watershed(image, markers)
image[markers == -1] = [0, 0, 0]
plt.axis("off")
plt.imshow(image)
            </pre>
        </div>
    </div>

    <div class="code-section">
        <h2>3. Geometric Transformations</h2>
        <p>This snippet demonstrates translation, scaling, rotation, affine transformation, and perspective transformation.</p>
        <div class="code-block">
            <pre>
import cv2
import numpy as np
image = cv2.imread('path_to_image.jpg')

# Translation
height, width = image.shape[:2]
translation_matrix = np.float32([[1, 0, 100], [0, 1, 50]])
translated_image = cv2.warpAffine(image, translation_matrix, (width, height))

# Scaling
scaled_image = cv2.resize(image, None, fx=0.5, fy=0.5)

# Rotation
center = (width // 2, height // 2)
rotation_matrix = cv2.getRotationMatrix2D(center, 45, 1)
rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))

# Affine Transformation
pts1 = np.float32([[50, 50], [200, 50], [50, 200]])
pts2 = np.float32([[10, 100], [200, 50], [100, 250]])
affine_matrix = cv2.getAffineTransform(pts1, pts2)
affine_image = cv2.warpAffine(image, affine_matrix, (width, height))

# Perspective Transformation
pts1 = np.float32([[0, 0], [width - 1, 0], [0, height - 1], [width - 1, height - 1]])
pts2 = np.float32([[0, 0], [width - 1, 0], [int(0.33 * width), height - 1], [int(0.66 * width), height - 1]])
perspective_matrix = cv2.getPerspectiveTransform(pts1, pts2)
perspective_image = cv2.warpPerspective(image, perspective_matrix, (width, height))
            </pre>
        </div>
    </div>

    <div class="code-section">
        <h2>4. Perspective Transformation</h2>
        <p>This snippet applies a simple perspective transformation to an image.</p>
        <div class="code-block">
            <pre>
import cv2
import numpy as np
from google.colab.patches import cv2_imshow
image = cv2.imread("chessboard.jpg")
height, width = image.shape[:2]
pts1 = np.float32([[0, 0], [width - 1, 0], [0, height - 1], [width - 1, height - 1]])
pts2 = np.float32([[0, 0], [width - 1, 0], [int(0.33 * width), height - 1], [int(0.66 * width), height - 1]])
perspective_matrix = cv2.getPerspectiveTransform(pts1, pts2)
perspective_image = cv2.warpPerspective(image, perspective_matrix, (width, height))
cv2_imshow(perspective_image)
            </pre>
        </div>
    </div>

    <div class="code-section">
        <h2>5. Camera Calibration</h2>
        <p>This snippet calibrates a camera using chessboard images.</p>
        <div class="code-block">
            <pre>
import numpy as np
import cv2
from google.colab.patches import cv2_imshow
image = cv2.imread("chessboard.jpg")
objp = np.zeros(((6*7),3),np.float32)
objp[:,:2] = np.mgrid[:7,:6].T.reshape(-1,2)
objpoints = []
imgpoints = []
gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
ret,corners = cv2.findChessboardCorners(gray,(7,6),None)
if ret:
  objpoints.append(objp)
  corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),None)
  image = cv2.drawChessboardCorners(image,(7,6),corners2,ret)
  imgpoints.append(corners2)
  cv2_imshow(image)
if objpoints and imgpoints:
  h,w = image.shape[:2]
  ret,m,d,rvecs,tvecs = cv2.calibrateCamera(objpoints,imgpoints,(w,h),None,None)
  print(m)
  print(d)
            </pre>
        </div>
    </div>

    <div class="code-section">
        <h2>6. Fundamental Matrix</h2>
        <p>This snippet finds the fundamental matrix between two images using ORB and BFMatcher.</p>
        <div class="code-block">
            <pre>
import cv2
import numpy as np
from google.colab.patches import cv2_imshow
img1 = cv2.imread("chessboard.jpg")
img2 = cv2.imread("chessboard.jpg")
kp1,des1 = cv2.ORB_create().detectAndCompute(img1,None)
kp2,des2 = cv2.ORB_create().detectAndCompute(img2,None)
matches = cv2.BFMatcher().match(des1,des2)
pt1 = np.float32([kp1[m.queryIdx].pt for m in matches])
pt2 = np.float32([kp2[m.trainIdx].pt for m in matches])
F, _ = cv2.findFundamentalMat(pt1,pt2)
print(F)

cv2_imshow(cv2.drawMatches(img1,kp1,img2,kp2,matches[:10],None))


#7

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

image = cv2.imread("chessboard.jpg")
sift = cv2.SIFT_create()
kp,des = sift.detectAndCompute(img,None)
img = cv2.drawKeypoints(img,kp,None)
cv2_imshow(img)
            </pre>
        </div>
    </div>
</body>
</html>
